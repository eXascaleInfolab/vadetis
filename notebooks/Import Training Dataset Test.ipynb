{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vadetisweb.models import User, Location, TimeSeries, DataSet\n",
    "import pandas as pd\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    ts_name      unit     value  class\n",
      "time                                                  \n",
      "2017-04-01 00:00:00   TEST0  Quantity  1.000000      0\n",
      "2017-04-01 01:00:00   TEST0  Quantity  1.090392      0\n",
      "2017-04-01 02:00:00   TEST0  Quantity  1.180271      0\n",
      "2017-04-01 03:00:00   TEST0  Quantity  1.269125      0\n",
      "2017-04-01 04:00:00   TEST0  Quantity  1.356450      0\n",
      "...                     ...       ...       ...    ...\n",
      "2017-05-12 11:00:00   TEST9  Quantity  1.458251      0\n",
      "2017-05-12 12:00:00   TEST9  Quantity  1.543550      0\n",
      "2017-05-12 13:00:00   TEST9  Quantity  1.630875      0\n",
      "2017-05-12 14:00:00   TEST9  Quantity  1.719729      0\n",
      "2017-05-12 15:00:00   TEST9  Quantity  1.809608      0\n",
      "\n",
      "[10000 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "df_read = pd.read_csv('/Users/adrian/Uni/MasterThesis/new_test_data/synthetic/test_data_sin/test_data_sin_with_class_train.csv',\n",
    "                                  sep=';',\n",
    "                                  parse_dates=['time'],\n",
    "                                  infer_datetime_format=True,\n",
    "                                  index_col='time')\n",
    "print(df_read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x11ce4b278>\n"
     ]
    }
   ],
   "source": [
    "group_by_ts_name = df_read.groupby('ts_name')\n",
    "print(group_by_ts_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts_name\n",
      "TEST0    [Quantity]\n",
      "TEST1    [Quantity]\n",
      "TEST2    [Quantity]\n",
      "TEST3    [Quantity]\n",
      "TEST4    [Quantity]\n",
      "TEST5    [Quantity]\n",
      "TEST6    [Quantity]\n",
      "TEST7    [Quantity]\n",
      "TEST8    [Quantity]\n",
      "TEST9    [Quantity]\n",
      "dtype: object\n",
      "Quantity\n",
      "Quantity\n",
      "Quantity\n",
      "Quantity\n",
      "Quantity\n",
      "Quantity\n",
      "Quantity\n",
      "Quantity\n",
      "Quantity\n",
      "Quantity\n"
     ]
    }
   ],
   "source": [
    "group_by_ts_name = df_read.groupby('ts_name')\n",
    "df_ts_unit = group_by_ts_name.apply(lambda x: x['unit'].unique())\n",
    "print(df_ts_unit)\n",
    "for idx, row in df_ts_unit.items():\n",
    "    print(row[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts_name                 TEST0     TEST1     TEST2     TEST3     TEST4  \\\n",
      "time                                                                    \n",
      "2017-04-01 00:00:00  1.000000  1.100000  1.200000  1.300000  1.400000   \n",
      "2017-04-01 01:00:00  1.090392  1.190392  1.290392  1.390392  1.490392   \n",
      "2017-04-01 02:00:00  1.180271  1.280271  1.380271  1.480271  1.580271   \n",
      "2017-04-01 03:00:00  1.269125  1.369125  1.469125  1.569125  1.669125   \n",
      "2017-04-01 04:00:00  1.356450  1.456450  1.556450  1.656450  1.756450   \n",
      "...                       ...       ...       ...       ...       ...   \n",
      "2017-05-12 11:00:00  0.558251  0.658251  0.758251  0.858251  0.958251   \n",
      "2017-05-12 12:00:00  0.643550  0.743550  0.843550  0.943550  1.043550   \n",
      "2017-05-12 13:00:00  0.730875  0.830875  0.930875  1.030875  1.130875   \n",
      "2017-05-12 14:00:00  0.819729  0.919729  1.019729  1.119729  1.219729   \n",
      "2017-05-12 15:00:00  0.909608  1.009608  1.109608  1.209608  1.309608   \n",
      "\n",
      "ts_name                 TEST5     TEST6     TEST7     TEST8     TEST9  \n",
      "time                                                                   \n",
      "2017-04-01 00:00:00  1.500000  1.600000  1.700000  1.800000  1.900000  \n",
      "2017-04-01 01:00:00  1.590392  1.690392  1.790392  1.890392  1.990392  \n",
      "2017-04-01 02:00:00  1.680271  1.780271  1.880271  1.980271  2.080271  \n",
      "2017-04-01 03:00:00  1.769125  1.869125  1.969125  2.069125  2.169125  \n",
      "2017-04-01 04:00:00  1.856450  1.956450  2.056450  2.156450  2.256450  \n",
      "...                       ...       ...       ...       ...       ...  \n",
      "2017-05-12 11:00:00  1.058251  1.158251  1.258251  1.358251  1.458251  \n",
      "2017-05-12 12:00:00  1.143550  1.243550  1.343550  1.443550  1.543550  \n",
      "2017-05-12 13:00:00  1.230875  1.330875  1.430875  1.530875  1.630875  \n",
      "2017-05-12 14:00:00  1.319729  1.419729  1.519729  1.619729  1.719729  \n",
      "2017-05-12 15:00:00  1.409608  1.509608  1.609608  1.709608  1.809608  \n",
      "\n",
      "[1000 rows x 10 columns]\n",
      "ts_name\n",
      "TEST0    [Quantity]\n",
      "TEST1    [Quantity]\n",
      "TEST2    [Quantity]\n",
      "TEST3    [Quantity]\n",
      "TEST4    [Quantity]\n",
      "TEST5    [Quantity]\n",
      "TEST6    [Quantity]\n",
      "TEST7    [Quantity]\n",
      "TEST8    [Quantity]\n",
      "TEST9    [Quantity]\n",
      "dtype: object\n",
      "TEST0\n",
      "['Quantity']\n",
      "TEST1\n",
      "['Quantity']\n",
      "TEST2\n",
      "['Quantity']\n",
      "TEST3\n",
      "['Quantity']\n",
      "TEST4\n",
      "['Quantity']\n",
      "TEST5\n",
      "['Quantity']\n",
      "TEST6\n",
      "['Quantity']\n",
      "TEST7\n",
      "['Quantity']\n",
      "TEST8\n",
      "['Quantity']\n",
      "TEST9\n",
      "['Quantity']\n",
      "ts_name                 TEST0     TEST1     TEST2     TEST3     TEST4  \\\n",
      "time                                                                    \n",
      "2017-04-01 00:00:00  1.000000  1.100000  1.200000  1.300000  1.400000   \n",
      "2017-04-01 01:00:00  1.090392  1.190392  1.290392  1.390392  1.490392   \n",
      "2017-04-01 02:00:00  1.180271  1.280271  1.380271  1.480271  1.580271   \n",
      "2017-04-01 03:00:00  1.269125  1.369125  1.469125  1.569125  1.669125   \n",
      "2017-04-01 04:00:00  1.356450  1.456450  1.556450  1.656450  1.756450   \n",
      "...                       ...       ...       ...       ...       ...   \n",
      "2017-05-12 11:00:00  0.558251  0.658251  0.758251  0.858251  0.958251   \n",
      "2017-05-12 12:00:00  0.643550  0.743550  0.843550  0.943550  1.043550   \n",
      "2017-05-12 13:00:00  0.730875  0.830875  0.930875  1.030875  1.130875   \n",
      "2017-05-12 14:00:00  0.819729  0.919729  1.019729  1.119729  1.219729   \n",
      "2017-05-12 15:00:00  0.909608  1.009608  1.109608  1.209608  1.309608   \n",
      "\n",
      "ts_name                 TEST5     TEST6     TEST7     TEST8     TEST9  \n",
      "time                                                                   \n",
      "2017-04-01 00:00:00  1.500000  1.600000  1.700000  1.800000  1.900000  \n",
      "2017-04-01 01:00:00  1.590392  1.690392  1.790392  1.890392  1.990392  \n",
      "2017-04-01 02:00:00  1.680271  1.780271  1.880271  1.980271  2.080271  \n",
      "2017-04-01 03:00:00  1.769125  1.869125  1.969125  2.069125  2.169125  \n",
      "2017-04-01 04:00:00  1.856450  1.956450  2.056450  2.156450  2.256450  \n",
      "...                       ...       ...       ...       ...       ...  \n",
      "2017-05-12 11:00:00  1.058251  1.158251  1.258251  1.358251  1.458251  \n",
      "2017-05-12 12:00:00  1.143550  1.243550  1.343550  1.443550  1.543550  \n",
      "2017-05-12 13:00:00  1.230875  1.330875  1.430875  1.530875  1.630875  \n",
      "2017-05-12 14:00:00  1.319729  1.419729  1.519729  1.619729  1.719729  \n",
      "2017-05-12 15:00:00  1.409608  1.509608  1.609608  1.709608  1.809608  \n",
      "\n",
      "[1000 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "df = df_read.pivot(columns='ts_name', values='value')\n",
    "print(df)\n",
    "# check each series must have same unit\n",
    "group_by_ts_name = df_read.groupby('ts_name')\n",
    "df_ts_unit = group_by_ts_name.apply(lambda x: x['unit'].unique())\n",
    "print(df_ts_unit)\n",
    "for idx, row in df_ts_unit.items():\n",
    "    print(idx)\n",
    "    print(row)\n",
    "    df.rename(columns={idx : 1})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts_name              TEST0  TEST1  TEST2  TEST3  TEST4  TEST5  TEST6  TEST7  \\\n",
      "time                                                                          \n",
      "2017-04-01 00:00:00  False  False  False  False  False  False  False  False   \n",
      "2017-04-01 01:00:00  False  False  False  False  False  False  False  False   \n",
      "2017-04-01 02:00:00  False  False  False  False  False  False  False  False   \n",
      "2017-04-01 03:00:00  False  False  False  False  False  False  False  False   \n",
      "2017-04-01 04:00:00  False  False  False  False  False  False  False  False   \n",
      "...                    ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "2017-05-12 11:00:00  False  False  False  False  False  False  False  False   \n",
      "2017-05-12 12:00:00  False  False  False  False  False  False  False  False   \n",
      "2017-05-12 13:00:00  False  False  False  False  False  False  False  False   \n",
      "2017-05-12 14:00:00  False  False  False  False  False  False  False  False   \n",
      "2017-05-12 15:00:00  False  False  False  False  False  False  False  False   \n",
      "\n",
      "ts_name              TEST8  TEST9  \n",
      "time                               \n",
      "2017-04-01 00:00:00  False  False  \n",
      "2017-04-01 01:00:00  False  False  \n",
      "2017-04-01 02:00:00  False  False  \n",
      "2017-04-01 03:00:00  False  False  \n",
      "2017-04-01 04:00:00  False  False  \n",
      "...                    ...    ...  \n",
      "2017-05-12 11:00:00  False  False  \n",
      "2017-05-12 12:00:00  False  False  \n",
      "2017-05-12 13:00:00  False  False  \n",
      "2017-05-12 14:00:00  False  False  \n",
      "2017-05-12 15:00:00  False  False  \n",
      "\n",
      "[1000 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "df_class = df_read.pivot(columns='ts_name', values='class')\n",
    "df_class = df_class.applymap(lambda x: True if x == 1 else False)\n",
    "print(df_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'idx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-788b23a00cbc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdfread\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_read\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0midx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfread\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'idx' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'idx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-93f5a55bdee8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_read\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0midx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_read\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'idx' is not defined"
     ]
    }
   ],
   "source": [
    "df_read.rename(columns={idx : 1})\n",
    "print(df_read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x1161f3b00>\n",
      "ts_name\n",
      "TEST0    [Quantity]\n",
      "TEST1    [Quantity]\n",
      "TEST2    [Quantity]\n",
      "TEST3    [Quantity]\n",
      "TEST4    [Quantity]\n",
      "TEST5    [Quantity]\n",
      "TEST6    [Quantity]\n",
      "TEST7    [Quantity]\n",
      "TEST8    [Quantity]\n",
      "TEST9    [Quantity]\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "group_by_ts_name = df_read.groupby('ts_name')\n",
    "print(group_by_ts_name)\n",
    "df_ts_unit = group_by_ts_name.apply(lambda x: x['unit'].unique())\n",
    "print(df_ts_unit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<QuerySet ['TEST0', 'TEST1', 'TEST2', 'TEST3', 'TEST4', 'TEST5', 'TEST6', 'TEST7', 'TEST8', 'TEST9']>\n",
      "['TEST0', 'TEST1', 'TEST2', 'TEST3', 'TEST4', 'TEST5', 'TEST6', 'TEST7', 'TEST8', 'TEST9']\n"
     ]
    }
   ],
   "source": [
    "ts_names_from_original = TimeSeries.objects.filter(datasets__id=5).values_list('name', flat=True)\n",
    "print(ts_names_from_original)\n",
    "print(list(ts_names_from_original))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TEST0',\n",
       " 'TEST1',\n",
       " 'TEST2',\n",
       " 'TEST3',\n",
       " 'TEST4',\n",
       " 'TEST5',\n",
       " 'TEST6',\n",
       " 'TEST7',\n",
       " 'TEST8',\n",
       " 'TEST9']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ts_unit.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_names_from_original = TimeSeries.objects.filter(datasets__id=5).values_list('name', flat=True)\n",
    "compare = lambda x, y: collections.Counter(x) == collections.Counter(y)\n",
    "compare(list(ts_names_from_original), df_ts_unit.index.tolist())\n",
    "if compare(list(ts_names_from_original), df_ts_unit.index.tolist()):\n",
    "    err_msg = \"Either some series are missing or some series are provided that are not in the original dataset.\"\n",
    "    raise ValueError(err_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_by_index = df_read.groupby(level=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "if group_by_index.apply(lambda x: x[\n",
    "    'ts_name'].duplicated()).any():  # true if any value is true => at least one duplicated index for a time series name\n",
    "    err_msg = \"Duplicated index for a time series found\"\n",
    "    raise ValueError(err_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Quantity']\n"
     ]
    }
   ],
   "source": [
    "units = []\n",
    "for idx, row in df_ts_unit.items():\n",
    "    unit = row[0]\n",
    "    if unit not in units:\n",
    "        units.append(unit)\n",
    "        \n",
    "print(units)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dataset = DataSet.objects.get(id=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_dataset.type_of_data is 'Same Units'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Same units'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_dataset.type_of_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<QuerySet []>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataSet.objects.filter(original_dataset__id=7, is_training_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
