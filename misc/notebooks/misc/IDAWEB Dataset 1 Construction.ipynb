{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json, csv, datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input\n",
    "\n",
    "file_path = '/home/adrian/Dokumente/real_data/IDAWEB/idaweb3/order50466/data3.csv'\n",
    "\n",
    "#output\n",
    "output_path = '/home/adrian/Dokumente/real_data/idaweb_out/'\n",
    "\n",
    "test_file_name = output_path + 'test.csv'\n",
    "train_file_name = output_path + 'train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_frame(file_path):\n",
    "    df = pd.read_csv(file_path,\n",
    "                     sep=';',\n",
    "                     parse_dates=['time'],\n",
    "                     infer_datetime_format=True,\n",
    "                     index_col='time',\n",
    "                     float_precision='high')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_file(outputfile):\n",
    "    with open(outputfile, 'w') as file_output:\n",
    "        writer = csv.writer(file_output, delimiter=';')\n",
    "        header = ['ts_name', 'time', 'unit', 'value', 'class']\n",
    "        writer.writerow(header)\n",
    "        \n",
    "def append_to_file(df, ts_name, unit, outputfile):\n",
    "    with open(outputfile, 'a') as file_output:\n",
    "        writer = csv.writer(file_output, delimiter=';')\n",
    "        for index, value in df.iteritems():\n",
    "            row = [ts_name, index.isoformat(), unit, value, 0]\n",
    "            writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_names_14 = ['REH', 'KLO', 'SHA', 'NABZUE', 'SMA', 'WYN', 'WAE', 'SAG', 'SRS', 'THU', 'VAD', 'RUE', 'HAI', 'VLS']\n",
    "ts_names_12 = ['REH', 'KLO', 'SHA', 'NABZUE', 'SMA', 'WYN', 'WAE', 'SAG', 'SRS', 'THU', 'VAD', 'RUE']\n",
    "ts_names_10 = ['REH', 'KLO', 'SHA', 'NABZUE', 'SMA', 'WYN', 'WAE', 'SAG', 'SRS', 'THU']\n",
    "ts_names_8 = ['REH', 'KLO', 'SHA', 'NABZUE', 'SMA','WYN', 'WAE', 'SAG']\n",
    "ts_names_6 = ['REH', 'KLO', 'SHA', 'NABZUE', 'SMA','WYN']\n",
    "ts_names_4 = ['REH', 'KLO', 'SHA', 'NABZUE']\n",
    "ts_names_2 = ['REH', 'KLO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read = load_data_frame(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_read.pivot(columns='ts_name', values='value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_output(df, ts_names, path_addition, file_suffix, ts_length=1000, training_length=500):\n",
    "    test_file_name = output_path + path_addition + 'test_' + file_suffix + '.csv'\n",
    "    train_file_name = output_path + path_addition + 'train_' + file_suffix + '.csv'\n",
    "    init_file(test_file_name)\n",
    "    init_file(train_file_name)\n",
    "    \n",
    "    for ts_name in ts_names:\n",
    "        df_set = df[ts_name]\n",
    "        df_test = df_set.iloc[0:1000]\n",
    "        df_train = df_set.iloc[1000:2000]\n",
    "    \n",
    "        append_to_file(df_test, ts_name, 'Celsius', test_file_name)\n",
    "        append_to_file(df_train, ts_name, 'Celsius', train_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_output(df, ts_names_14, 'set1/', file_suffix='14', ts_length=1000, training_length=500)\n",
    "generate_output(df, ts_names_12, 'set1/', file_suffix='12', ts_length=1000, training_length=500)\n",
    "generate_output(df, ts_names_10, 'set1/', file_suffix='10', ts_length=1000, training_length=500)\n",
    "generate_output(df, ts_names_8, 'set1/', file_suffix='8', ts_length=1000, training_length=500)\n",
    "generate_output(df, ts_names_6, 'set1/', file_suffix='6', ts_length=1000, training_length=500)\n",
    "generate_output(df, ts_names_4, 'set1/', file_suffix='4', ts_length=1000, training_length=500)\n",
    "generate_output(df, ts_names_2, 'set1/', file_suffix='2', ts_length=1000, training_length=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts_name              DLSAA  DLSTO  DLSTU  DLWEI   HAI  KLO  MMWEG  NABZUE  \\\n",
      "time                                                                        \n",
      "2017-04-01 00:00:00   10.1   12.1   10.8    5.5  13.1  7.9    6.6    13.1   \n",
      "2017-04-01 00:10:00   10.2   11.7    9.5    6.4  13.3  9.0    6.7    12.6   \n",
      "2017-04-01 00:20:00   10.0   11.5    9.2    6.3  12.6  8.8    5.7    12.5   \n",
      "2017-04-01 00:30:00    9.2   11.2    8.6    4.1  12.6  8.2    6.7    13.0   \n",
      "2017-04-01 00:40:00    9.0   11.1    8.8    5.3  12.8  7.8    7.6    12.8   \n",
      "...                    ...    ...    ...    ...   ...  ...    ...     ...   \n",
      "2017-04-30 23:10:00   13.2    5.0    6.3    6.2  10.0  5.8    3.8    10.4   \n",
      "2017-04-30 23:20:00   13.4    4.6    6.7    6.1  10.1  4.0    3.1    10.4   \n",
      "2017-04-30 23:30:00   13.2    4.3    7.5    5.6   9.9  4.1    3.8    10.5   \n",
      "2017-04-30 23:40:00   12.8    4.5    6.8    5.0  10.2  1.8    2.7    11.3   \n",
      "2017-04-30 23:50:00   12.6    4.3    6.9    5.3  10.4  3.7    2.6    11.1   \n",
      "\n",
      "ts_name              REH   RUE  ...   VAD   VEV  VIO   VIS  VIT   VLS   WAE  \\\n",
      "time                            ...                                           \n",
      "2017-04-01 00:00:00  9.7  13.2  ...  18.4  13.2  8.0  14.9  6.8   6.2  11.6   \n",
      "2017-04-01 00:10:00  8.3  13.0  ...  18.2  12.7  8.5  14.9  6.9  10.2  11.2   \n",
      "2017-04-01 00:20:00  8.8  13.1  ...  16.2  13.3  8.2  14.3  7.1  10.9  11.0   \n",
      "2017-04-01 00:30:00  7.8  13.0  ...  16.2  13.3  8.0  14.7  6.5  11.0  10.9   \n",
      "2017-04-01 00:40:00  7.9  13.3  ...  16.7  12.5  8.0  14.6  6.7  10.8  10.7   \n",
      "...                  ...   ...  ...   ...   ...  ...   ...  ...   ...   ...   \n",
      "2017-04-30 23:10:00  5.7  10.9  ...  14.9  11.7  5.1  10.7  5.3   3.7  10.8   \n",
      "2017-04-30 23:20:00  6.4  11.1  ...  15.1  11.3  5.9  10.8  4.8   3.8  10.8   \n",
      "2017-04-30 23:30:00  5.9  10.6  ...  14.6  11.3  5.7  10.7  4.0   4.1  10.8   \n",
      "2017-04-30 23:40:00  6.8  10.3  ...  14.6  11.0  5.5  10.8  3.3   3.8  11.3   \n",
      "2017-04-30 23:50:00  6.0  10.2  ...  14.5  10.6  5.2  10.8  2.5   3.8  11.0   \n",
      "\n",
      "ts_name               WFJ  WYN  ZER  \n",
      "time                                 \n",
      "2017-04-01 00:00:00  -8.0  6.5  5.9  \n",
      "2017-04-01 00:10:00  -7.8  6.2  6.4  \n",
      "2017-04-01 00:20:00  -8.3  6.1  5.8  \n",
      "2017-04-01 00:30:00  -8.2  6.3  6.3  \n",
      "2017-04-01 00:40:00  -7.8  6.2  5.2  \n",
      "...                   ...  ...  ...  \n",
      "2017-04-30 23:10:00 -12.2  7.8 -0.1  \n",
      "2017-04-30 23:20:00 -12.4  7.9 -0.7  \n",
      "2017-04-30 23:30:00 -11.8  7.8  0.2  \n",
      "2017-04-30 23:40:00 -11.3  8.5  0.2  \n",
      "2017-04-30 23:50:00 -12.1  8.4 -0.3  \n",
      "\n",
      "[4320 rows x 36 columns]\n"
     ]
    }
   ],
   "source": [
    "#Correlation\n",
    "\n",
    "df = df_read.pivot(columns='ts_name', values='value')\n",
    "df_no_na = df.dropna(axis=1, how='any')\n",
    "print(df_no_na)\n",
    "df_corr = df_no_na.corr(method='pearson')\n",
    "df_corr = df_corr.round(2)\n",
    "df_corr.to_csv(output_path + 'set1/' +'corr.csv', index = True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_set(path, files, file_set_names, file_suffix):\n",
    "    test_file_name = output_path + path + 'test_' + file_suffix + '.csv'\n",
    "    train_file_name = output_path + path + 'train_' + file_suffix + '.csv'\n",
    "    init_file(test_file_name)\n",
    "    init_file(train_file_name)\n",
    "    \n",
    "    for entry in files:\n",
    "        ts_name = entry['name']\n",
    "        if ts_name in file_set_names:\n",
    "            file_path = entry['file_path']\n",
    "            df = load_data_frame(ts_name, file_path)\n",
    "            df = time_index_to_dt(df)\n",
    "            print(ts_name + \"\\t anomalies \" \n",
    "                  + str(df.loc[df['class']==1].shape[0]) \n",
    "                  + '\\t values ' + str(df.shape[0])\n",
    "                  + '\\t min ' + str(df.loc[df['class']==0, 'value'].min()) \n",
    "                  + '\\t max ' + str(df.loc[df['class']==0, 'value'].max()))\n",
    "            df_test = df.iloc[0:710]\n",
    "            print('test' + \"\\t anomalies \" + str(df_test.loc[df_test['class']==1].shape[0]) + '\\t values ' + str(df_test.shape[0]))\n",
    "\n",
    "            df_train = df.iloc[710:1421]\n",
    "            print('train' + \"\\t anomalies \" + str(df_train.loc[df_train['class']==1].shape[0]) + '\\t values ' + str(df_train.shape[0]))\n",
    "            print('\\n')\n",
    "            append_to_file(df_test, test_file_name)\n",
    "            append_to_file(df_train, train_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
