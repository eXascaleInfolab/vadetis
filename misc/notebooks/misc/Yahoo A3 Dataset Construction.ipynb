{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json, csv, datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input\n",
    "\n",
    "yahoo_path = '/home/adrian/Dokumente/real_data/ydata-labeled-time-series-anomalies-v1_0'\n",
    "\n",
    "a1_path = '/A1Benchmark/'\n",
    "a2_path = '/A2Benchmark/'\n",
    "a3_path = '/A3Benchmark/'\n",
    "a4_path = '/A4Benchmark/'\n",
    "\n",
    "a1_elements = np.arange(1, 68).tolist()\n",
    "a234_elements = np.arange(1, 101).tolist()\n",
    "\n",
    "a1files = [{ 'name' : 'TS' + str(x), 'file_path' : yahoo_path + a1_path + 'real_' + str(x) + '.csv' } for x in a1_elements]\n",
    "a2files = [{ 'name' : 'TS' + str(x), 'file_path' : yahoo_path + a2_path + 'synthetic_' + str(x) + '.csv' } for x in a234_elements]\n",
    "a3files = [{ 'name' : 'TS' + str(x), 'file_path' : yahoo_path + a3_path + 'A3Benchmark-TS' + str(x) + '.csv' } for x in a234_elements]\n",
    "a4files = [{ 'name' : 'TS' + str(x), 'file_path' : yahoo_path + a4_path + 'A4Benchmark-TS' + str(x) + '.csv' } for x in a234_elements]\n",
    "\n",
    "#output\n",
    "output_path = '/home/adrian/Dokumente/real_data/yahoo_out2'\n",
    "\n",
    "#test_file_name = output_path + a2_path + 'test.csv'\n",
    "#train_file_name = output_path + a2_path + 'train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_frame(ts_name, file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    df.insert(0, 'ts_name', ts_name)\n",
    "    df.insert(2, 'unit', \"Value\")\n",
    "    df = df.rename(columns={'timestamps': 'time', 'anomaly' : 'class'})\n",
    "    df = df.drop(columns=['changepoint', 'trend', 'noise', 'seasonality1', 'seasonality2', 'seasonality3'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_index_to_dt(df):\n",
    "    for idx, row in df.iterrows():\n",
    "        dt = datetime.datetime.fromtimestamp(row['time'])\n",
    "        df.loc[idx, 'time'] = dt\n",
    "    return df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_file(outputfile):\n",
    "    with open(outputfile, 'w') as file_output:\n",
    "        writer = csv.writer(file_output, delimiter=';')\n",
    "        header = ['ts_name', 'time', 'unit', 'value', 'class']\n",
    "        writer.writerow(header)\n",
    "        \n",
    "def append_to_file(df, outputfile):\n",
    "    with open(outputfile, 'a') as file_output:\n",
    "        writer = csv.writer(file_output, delimiter=';')\n",
    "        for index, row in df.iterrows():\n",
    "            row = [row[0], row[1].isoformat(), row[2], row[3], row[4]]\n",
    "            writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S1 set\n",
    "names_set_a3_s1 = ['TS' + str(x) for x in [22, 3, 5, 11, 13, 16, 17, 25]]\n",
    "file_suffix_s1 = \"s1\"\n",
    "# S2 set\n",
    "names_set_a3_s2 = ['TS' + str(x) for x in [22, 3, 5, 11, 13, 16, 17]]\n",
    "file_suffix_s2 = \"s2\"\n",
    "# S3 set\n",
    "names_set_a3_s3 = ['TS' + str(x) for x in [22, 3, 5, 11, 13, 16]]\n",
    "file_suffix_s3 = \"s3\"\n",
    "# S4 set\n",
    "names_set_a3_s4 = ['TS' + str(x) for x in [22, 3, 5, 11, 13]]\n",
    "file_suffix_s4 = \"s4\"\n",
    "# S5 set\n",
    "names_set_a3_s5 = ['TS' + str(x) for x in [22, 3, 5, 11]]\n",
    "file_suffix_s5 = \"s5\"\n",
    "# S6 set\n",
    "names_set_a3_s6 = ['TS' + str(x) for x in [22, 3, 5]]\n",
    "file_suffix_s6 = \"s6\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_set(path, files, file_set_names, file_suffix):\n",
    "    test_file_name = output_path + path + 'test_' + file_suffix + '.csv'\n",
    "    train_file_name = output_path + path + 'train_' + file_suffix + '.csv'\n",
    "    init_file(test_file_name)\n",
    "    init_file(train_file_name)\n",
    "    \n",
    "    for entry in files:\n",
    "        ts_name = entry['name']\n",
    "        if ts_name in file_set_names:\n",
    "            file_path = entry['file_path']\n",
    "            df = load_data_frame(ts_name, file_path)\n",
    "            df = time_index_to_dt(df)\n",
    "            print(ts_name + \"\\t anomalies \" \n",
    "                  + str(df.loc[df['class']==1].shape[0]) \n",
    "                  + '\\t values ' + str(df.shape[0])\n",
    "                  + '\\t min ' + str(df.loc[df['class']==0, 'value'].min()) \n",
    "                  + '\\t max ' + str(df.loc[df['class']==0, 'value'].max()))\n",
    "            df_test = df.iloc[0:1000]\n",
    "            print('test' + \"\\t anomalies \" + str(df_test.loc[df_test['class']==1].shape[0]) + '\\t values ' + str(df_test.shape[0]))\n",
    "\n",
    "            df_train = df.iloc[1000:1681]\n",
    "            print('train' + \"\\t anomalies \" + str(df_train.loc[df_train['class']==1].shape[0]) + '\\t values ' + str(df_train.shape[0]))\n",
    "            print('\\n')\n",
    "            append_to_file(df_test, test_file_name)\n",
    "            append_to_file(df_train, train_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TS3\t anomalies 6\t values 1680\t min -455.124029606913\t max 3793.35711668\n",
      "test\t anomalies 3\t values 1000\n",
      "train\t anomalies 3\t values 680\n",
      "\n",
      "\n",
      "TS5\t anomalies 2\t values 1680\t min -692.5193251525819\t max 4006.7266584886997\n",
      "test\t anomalies 1\t values 1000\n",
      "train\t anomalies 1\t values 680\n",
      "\n",
      "\n",
      "TS11\t anomalies 7\t values 1680\t min -693.754935483698\t max 4003.2504520817297\n",
      "test\t anomalies 5\t values 1000\n",
      "train\t anomalies 2\t values 680\n",
      "\n",
      "\n",
      "TS13\t anomalies 9\t values 1680\t min -1630.7865546076\t max 3384.70905885213\n",
      "test\t anomalies 7\t values 1000\n",
      "train\t anomalies 2\t values 680\n",
      "\n",
      "\n",
      "TS16\t anomalies 9\t values 1680\t min -1701.08492942196\t max 6579.30692418012\n",
      "test\t anomalies 4\t values 1000\n",
      "train\t anomalies 5\t values 680\n",
      "\n",
      "\n",
      "TS17\t anomalies 1\t values 1680\t min -739.206063334008\t max 5749.1714457047\n",
      "test\t anomalies 1\t values 1000\n",
      "train\t anomalies 0\t values 680\n",
      "\n",
      "\n",
      "TS22\t anomalies 4\t values 1680\t min -1839.3630921341198\t max 7006.206125087901\n",
      "test\t anomalies 2\t values 1000\n",
      "train\t anomalies 2\t values 680\n",
      "\n",
      "\n",
      "TS25\t anomalies 2\t values 1680\t min -446.966466307631\t max 3807.9678165871296\n",
      "test\t anomalies 0\t values 1000\n",
      "train\t anomalies 2\t values 680\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "create_set(a3_path, a3files, names_set_a3_s1, file_suffix_s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TS3\t anomalies 6\t values 1680\t min -455.124029606913\t max 3793.35711668\n",
      "test\t anomalies 3\t values 1000\n",
      "train\t anomalies 3\t values 680\n",
      "\n",
      "\n",
      "TS5\t anomalies 2\t values 1680\t min -692.5193251525819\t max 4006.7266584886997\n",
      "test\t anomalies 1\t values 1000\n",
      "train\t anomalies 1\t values 680\n",
      "\n",
      "\n",
      "TS11\t anomalies 7\t values 1680\t min -693.754935483698\t max 4003.2504520817297\n",
      "test\t anomalies 5\t values 1000\n",
      "train\t anomalies 2\t values 680\n",
      "\n",
      "\n",
      "TS13\t anomalies 9\t values 1680\t min -1630.7865546076\t max 3384.70905885213\n",
      "test\t anomalies 7\t values 1000\n",
      "train\t anomalies 2\t values 680\n",
      "\n",
      "\n",
      "TS16\t anomalies 9\t values 1680\t min -1701.08492942196\t max 6579.30692418012\n",
      "test\t anomalies 4\t values 1000\n",
      "train\t anomalies 5\t values 680\n",
      "\n",
      "\n",
      "TS17\t anomalies 1\t values 1680\t min -739.206063334008\t max 5749.1714457047\n",
      "test\t anomalies 1\t values 1000\n",
      "train\t anomalies 0\t values 680\n",
      "\n",
      "\n",
      "TS22\t anomalies 4\t values 1680\t min -1839.3630921341198\t max 7006.206125087901\n",
      "test\t anomalies 2\t values 1000\n",
      "train\t anomalies 2\t values 680\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "create_set(a3_path, a3files, names_set_a3_s2, file_suffix_s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TS3\t anomalies 6\t values 1680\t min -455.124029606913\t max 3793.35711668\n",
      "test\t anomalies 3\t values 1000\n",
      "train\t anomalies 3\t values 680\n",
      "\n",
      "\n",
      "TS5\t anomalies 2\t values 1680\t min -692.5193251525819\t max 4006.7266584886997\n",
      "test\t anomalies 1\t values 1000\n",
      "train\t anomalies 1\t values 680\n",
      "\n",
      "\n",
      "TS11\t anomalies 7\t values 1680\t min -693.754935483698\t max 4003.2504520817297\n",
      "test\t anomalies 5\t values 1000\n",
      "train\t anomalies 2\t values 680\n",
      "\n",
      "\n",
      "TS13\t anomalies 9\t values 1680\t min -1630.7865546076\t max 3384.70905885213\n",
      "test\t anomalies 7\t values 1000\n",
      "train\t anomalies 2\t values 680\n",
      "\n",
      "\n",
      "TS16\t anomalies 9\t values 1680\t min -1701.08492942196\t max 6579.30692418012\n",
      "test\t anomalies 4\t values 1000\n",
      "train\t anomalies 5\t values 680\n",
      "\n",
      "\n",
      "TS22\t anomalies 4\t values 1680\t min -1839.3630921341198\t max 7006.206125087901\n",
      "test\t anomalies 2\t values 1000\n",
      "train\t anomalies 2\t values 680\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "create_set(a3_path, a3files, names_set_a3_s3, file_suffix_s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TS3\t anomalies 6\t values 1680\t min -455.124029606913\t max 3793.35711668\n",
      "test\t anomalies 3\t values 1000\n",
      "train\t anomalies 3\t values 680\n",
      "\n",
      "\n",
      "TS5\t anomalies 2\t values 1680\t min -692.5193251525819\t max 4006.7266584886997\n",
      "test\t anomalies 1\t values 1000\n",
      "train\t anomalies 1\t values 680\n",
      "\n",
      "\n",
      "TS11\t anomalies 7\t values 1680\t min -693.754935483698\t max 4003.2504520817297\n",
      "test\t anomalies 5\t values 1000\n",
      "train\t anomalies 2\t values 680\n",
      "\n",
      "\n",
      "TS13\t anomalies 9\t values 1680\t min -1630.7865546076\t max 3384.70905885213\n",
      "test\t anomalies 7\t values 1000\n",
      "train\t anomalies 2\t values 680\n",
      "\n",
      "\n",
      "TS22\t anomalies 4\t values 1680\t min -1839.3630921341198\t max 7006.206125087901\n",
      "test\t anomalies 2\t values 1000\n",
      "train\t anomalies 2\t values 680\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "create_set(a3_path, a3files, names_set_a3_s4, file_suffix_s4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TS3\t anomalies 6\t values 1680\t min -455.124029606913\t max 3793.35711668\n",
      "test\t anomalies 3\t values 1000\n",
      "train\t anomalies 3\t values 680\n",
      "\n",
      "\n",
      "TS5\t anomalies 2\t values 1680\t min -692.5193251525819\t max 4006.7266584886997\n",
      "test\t anomalies 1\t values 1000\n",
      "train\t anomalies 1\t values 680\n",
      "\n",
      "\n",
      "TS11\t anomalies 7\t values 1680\t min -693.754935483698\t max 4003.2504520817297\n",
      "test\t anomalies 5\t values 1000\n",
      "train\t anomalies 2\t values 680\n",
      "\n",
      "\n",
      "TS22\t anomalies 4\t values 1680\t min -1839.3630921341198\t max 7006.206125087901\n",
      "test\t anomalies 2\t values 1000\n",
      "train\t anomalies 2\t values 680\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "create_set(a3_path, a3files, names_set_a3_s5, file_suffix_s5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TS3\t anomalies 6\t values 1680\t min -455.124029606913\t max 3793.35711668\n",
      "test\t anomalies 3\t values 1000\n",
      "train\t anomalies 3\t values 680\n",
      "\n",
      "\n",
      "TS5\t anomalies 2\t values 1680\t min -692.5193251525819\t max 4006.7266584886997\n",
      "test\t anomalies 1\t values 1000\n",
      "train\t anomalies 1\t values 680\n",
      "\n",
      "\n",
      "TS22\t anomalies 4\t values 1680\t min -1839.3630921341198\t max 7006.206125087901\n",
      "test\t anomalies 2\t values 1000\n",
      "train\t anomalies 2\t values 680\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "create_set(a3_path, a3files, names_set_a3_s6, file_suffix_s6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S1\n",
    "test_file_name_s1 = output_path + a3_path + 'test_s1.csv'\n",
    "train_file_name_s1 = output_path + a3_path + 'train_s1.csv'\n",
    "init_file(test_file_name_s1)\n",
    "init_file(train_file_name_s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TS3\t anomalies 6\t values 1680\t min -455.124029606913\t max 3793.35711668\n",
      "test\t anomalies 3\t values 1000\n",
      "train\t anomalies 1\t values 400\n",
      "\n",
      "\n",
      "TS5\t anomalies 2\t values 1680\t min -692.5193251525819\t max 4006.7266584886997\n",
      "test\t anomalies 1\t values 1000\n",
      "train\t anomalies 0\t values 400\n",
      "\n",
      "\n",
      "TS11\t anomalies 7\t values 1680\t min -693.754935483698\t max 4003.2504520817297\n",
      "test\t anomalies 5\t values 1000\n",
      "train\t anomalies 2\t values 400\n",
      "\n",
      "\n",
      "TS13\t anomalies 9\t values 1680\t min -1630.7865546076\t max 3384.70905885213\n",
      "test\t anomalies 7\t values 1000\n",
      "train\t anomalies 2\t values 400\n",
      "\n",
      "\n",
      "TS16\t anomalies 9\t values 1680\t min -1701.08492942196\t max 6579.30692418012\n",
      "test\t anomalies 4\t values 1000\n",
      "train\t anomalies 4\t values 400\n",
      "\n",
      "\n",
      "TS17\t anomalies 1\t values 1680\t min -739.206063334008\t max 5749.1714457047\n",
      "test\t anomalies 1\t values 1000\n",
      "train\t anomalies 0\t values 400\n",
      "\n",
      "\n",
      "TS22\t anomalies 4\t values 1680\t min -1839.3630921341198\t max 7006.206125087901\n",
      "test\t anomalies 2\t values 1000\n",
      "train\t anomalies 2\t values 400\n",
      "\n",
      "\n",
      "TS25\t anomalies 2\t values 1680\t min -446.966466307631\t max 3807.9678165871296\n",
      "test\t anomalies 0\t values 1000\n",
      "train\t anomalies 2\t values 400\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for entry in a3files:\n",
    "    ts_name = entry['name']\n",
    "    if ts_name in names_set_a3_s1:\n",
    "        file_path = entry['file_path']\n",
    "        df = load_data_frame(ts_name, file_path)\n",
    "        df = time_index_to_dt(df)\n",
    "        print(ts_name + \"\\t anomalies \" \n",
    "              + str(df.loc[df['class']==1].shape[0]) \n",
    "              + '\\t values ' + str(df.shape[0])\n",
    "              + '\\t min ' + str(df.loc[df['class']==0, 'value'].min()) \n",
    "              + '\\t max ' + str(df.loc[df['class']==0, 'value'].max()))\n",
    "        df_test = df.iloc[0:1000]\n",
    "        print('test' + \"\\t anomalies \" + str(df_test.loc[df_test['class']==1].shape[0]) + '\\t values ' + str(df_test.shape[0]))\n",
    "\n",
    "        df_train = df.iloc[1001:1681]\n",
    "        print('train' + \"\\t anomalies \" + str(df_train.loc[df_train['class']==1].shape[0]) + '\\t values ' + str(df_train.shape[0]))\n",
    "        print('\\n')\n",
    "        append_to_file(df_test, test_file_name_s1)\n",
    "        append_to_file(df_train, train_file_name_s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
