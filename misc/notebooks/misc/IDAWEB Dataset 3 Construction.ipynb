{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json, csv, datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input\n",
    "\n",
    "file_path = '/home/adrian/Dokumente/real_data/IDAWEB/idaweb3/order47741/data3.csv'\n",
    "\n",
    "#output\n",
    "output_path = '/home/adrian/Dokumente/real_data/idaweb_out_s3/'\n",
    "\n",
    "test_file_name = output_path + 'test.csv'\n",
    "train_file_name = output_path + 'train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_frame(file_path):\n",
    "    df = pd.read_csv(file_path,\n",
    "                     sep=';',\n",
    "                     parse_dates=['time'],\n",
    "                     infer_datetime_format=True,\n",
    "                     index_col='time',\n",
    "                     float_precision='high')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_file(outputfile):\n",
    "    with open(outputfile, 'w') as file_output:\n",
    "        writer = csv.writer(file_output, delimiter=';')\n",
    "        header = ['ts_name', 'time', 'unit', 'value', 'class']\n",
    "        writer.writerow(header)\n",
    "        \n",
    "def append_to_file(df, ts_name, unit, outputfile):\n",
    "    with open(outputfile, 'a') as file_output:\n",
    "        writer = csv.writer(file_output, delimiter=';')\n",
    "        for index, value in df.iteritems():\n",
    "            row = [ts_name, index.isoformat(), unit, value, 0]\n",
    "            writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_names_9 = ['LUZ', 'RGNOT', 'MOA', 'KOP', 'LAG', 'OBR', 'LAE', 'ORO', 'PAY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read = load_data_frame(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_read.pivot(columns='ts_name', values='value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_output(df, ts_names, path_addition, file_suffix, ts_length=1000, training_length=500):\n",
    "    test_file_name = output_path + path_addition + 'test_' + file_suffix + '.csv'\n",
    "    train_file_name = output_path + path_addition + 'train_' + file_suffix + '.csv'\n",
    "    init_file(test_file_name)\n",
    "    init_file(train_file_name)\n",
    "    \n",
    "    for ts_name in ts_names:\n",
    "        df_set = df[ts_name]\n",
    "        df_test = df_set.iloc[0:1500]\n",
    "        df_train = df_set.iloc[1500:3000]\n",
    "    \n",
    "        append_to_file(df_test, ts_name, 'g/kg', test_file_name)\n",
    "        append_to_file(df_train, ts_name, 'g/kg', train_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_output(df, ts_names_9, 'set3/', file_suffix='9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts_name              ATT  BEH  BRL  CDF  CGI  CHB  COV  DOL  GEN  INT  ...  \\\n",
      "time                                                                   ...   \n",
      "2016-06-01 00:00:00  4.8  5.3  4.8  5.8  7.4  6.9  4.5  5.7  7.1  9.1  ...   \n",
      "2016-06-01 00:10:00  4.9  5.4  4.8  5.4  7.3  6.8  4.4  5.7  7.1  9.1  ...   \n",
      "2016-06-01 00:20:00  4.9  5.3  4.8  5.5  7.3  6.7  4.5  5.7  7.1  9.1  ...   \n",
      "2016-06-01 00:30:00  4.9  5.4  4.6  5.7  7.2  6.4  4.5  5.7  7.1  9.1  ...   \n",
      "2016-06-01 00:40:00  5.0  5.4  4.5  5.9  7.2  6.4  4.5  5.7  7.1  9.2  ...   \n",
      "\n",
      "ts_name              NAP  NAS  NEU  OBR  ORO  OTL  PAY  PIL  PIO  RGNOT  \n",
      "time                                                                     \n",
      "2016-06-01 00:00:00  6.5  5.4  7.9  9.8  7.1  9.0  7.2  5.8  8.1    8.5  \n",
      "2016-06-01 00:10:00  6.6  5.6  7.9  9.7  7.0  8.9  7.4  5.8  8.1    8.5  \n",
      "2016-06-01 00:20:00  6.5  5.5  7.8  9.6  7.0  8.9  7.2  5.9  8.0    8.4  \n",
      "2016-06-01 00:30:00  6.4  5.5  7.8  9.7  7.0  8.9  7.5  5.9  8.0    8.3  \n",
      "2016-06-01 00:40:00  6.4  5.4  8.0  9.7  7.1  8.8  7.4  5.8  8.1    8.4  \n",
      "\n",
      "[5 rows x 38 columns]\n",
      "ts_name   ATT   BEH   BRL   CDF   CGI   CHB   COV   DOL   GEN   INT  ...  \\\n",
      "ts_name                                                              ...   \n",
      "ATT      1.00  0.69  0.66  0.67  0.58  0.65  0.78  0.63  0.71  0.70  ...   \n",
      "BEH      0.69  1.00  0.61  0.66  0.61  0.61  0.78  0.57  0.76  0.71  ...   \n",
      "BRL      0.66  0.61  1.00  0.92  0.80  0.88  0.60  0.78  0.65  0.78  ...   \n",
      "CDF      0.67  0.66  0.92  1.00  0.84  0.89  0.61  0.79  0.66  0.82  ...   \n",
      "CGI      0.58  0.61  0.80  0.84  1.00  0.86  0.56  0.77  0.60  0.81  ...   \n",
      "\n",
      "ts_name   NAP   NAS   NEU   OBR   ORO   OTL   PAY   PIL   PIO  RGNOT  \n",
      "ts_name                                                               \n",
      "ATT      0.67  0.64  0.57  0.69  0.64  0.68  0.60  0.75  0.70   0.62  \n",
      "BEH      0.60  0.70  0.59  0.72  0.63  0.79  0.65  0.69  0.83   0.69  \n",
      "BRL      0.79  0.53  0.80  0.75  0.81  0.68  0.80  0.74  0.74   0.78  \n",
      "CDF      0.80  0.57  0.86  0.80  0.84  0.72  0.86  0.75  0.77   0.84  \n",
      "CGI      0.75  0.57  0.86  0.79  0.87  0.69  0.88  0.66  0.72   0.83  \n",
      "\n",
      "[5 rows x 38 columns]\n"
     ]
    }
   ],
   "source": [
    "#Correlation\n",
    "\n",
    "df = df_read.pivot(columns='ts_name', values='value')\n",
    "df = df[0:8000]\n",
    "df_no_na = df.dropna(axis=1, how='any')\n",
    "print(df_no_na.head())\n",
    "df_corr = df_no_na.corr(method='pearson')\n",
    "df_corr = df_corr.round(2)\n",
    "print(df_corr.head())\n",
    "df_corr.to_csv(output_path + 'set3/' +'corr.csv', index = True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts_name             WSLBAF WSLBTF WSLCIF WSLCLF WSLISF WSLJUF WSLLAF WSLNAF  \\\n",
      "time                                                                          \n",
      "2017-04-01 00:00:00      0   -0.1    NaN   -0.3   2659    4.2      2    0.4   \n",
      "2017-04-01 00:10:00      0      0    NaN   -2.6   2657    4.2      1    0.4   \n",
      "2017-04-01 00:20:00      0      0    NaN   -0.1   2695    4.3    0.6    0.4   \n",
      "2017-04-01 00:30:00      0      0    NaN   -1.1      -    4.2      1    0.4   \n",
      "2017-04-01 00:40:00      0      0    NaN   -0.3      -    4.2    4.1    0.4   \n",
      "...                    ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "2017-04-30 23:10:00      0      0      -   -0.1   2428    4.4    1.9    0.8   \n",
      "2017-04-30 23:20:00      0      0      -   -1.4   2366    4.3    0.4    0.9   \n",
      "2017-04-30 23:30:00      0      0      -   -0.7   2357    4.3    3.1      1   \n",
      "2017-04-30 23:40:00      0      0      -   -1.1   2350    4.3    1.4    0.7   \n",
      "2017-04-30 23:50:00      0      0      -   -0.5   2375    4.2      2    1.5   \n",
      "\n",
      "ts_name             WSLNEF WSLNOF WSLOTF WSLSCF WSLVOF WSLVSF  \n",
      "time                                                           \n",
      "2017-04-01 00:00:00   -0.2  -14.7      0    3.7      0      0  \n",
      "2017-04-01 00:10:00   -0.2  -14.7      0    3.7      0      0  \n",
      "2017-04-01 00:20:00   -0.2  -14.7      0    3.7      0      0  \n",
      "2017-04-01 00:30:00   -0.2  -14.6      0    3.7      0      0  \n",
      "2017-04-01 00:40:00   -0.2  -14.7      0    3.7      0      0  \n",
      "...                    ...    ...    ...    ...    ...    ...  \n",
      "2017-04-30 23:10:00   -0.2  -12.6      0    3.7      0      0  \n",
      "2017-04-30 23:20:00   -0.2  -12.6      0    3.7      0      0  \n",
      "2017-04-30 23:30:00   -0.2  -12.6      0    3.7      0      0  \n",
      "2017-04-30 23:40:00   -0.2  -12.6      0    3.7      0      0  \n",
      "2017-04-30 23:50:00   -0.2  -12.6      0    3.7      0      0  \n",
      "\n",
      "[4320 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_set(path, files, file_set_names, file_suffix):\n",
    "    test_file_name = output_path + path + 'test_' + file_suffix + '.csv'\n",
    "    train_file_name = output_path + path + 'train_' + file_suffix + '.csv'\n",
    "    init_file(test_file_name)\n",
    "    init_file(train_file_name)\n",
    "    \n",
    "    for entry in files:\n",
    "        ts_name = entry['name']\n",
    "        if ts_name in file_set_names:\n",
    "            file_path = entry['file_path']\n",
    "            df = load_data_frame(ts_name, file_path)\n",
    "            df = time_index_to_dt(df)\n",
    "            print(ts_name + \"\\t anomalies \" \n",
    "                  + str(df.loc[df['class']==1].shape[0]) \n",
    "                  + '\\t values ' + str(df.shape[0])\n",
    "                  + '\\t min ' + str(df.loc[df['class']==0, 'value'].min()) \n",
    "                  + '\\t max ' + str(df.loc[df['class']==0, 'value'].max()))\n",
    "            df_test = df.iloc[0:710]\n",
    "            print('test' + \"\\t anomalies \" + str(df_test.loc[df_test['class']==1].shape[0]) + '\\t values ' + str(df_test.shape[0]))\n",
    "\n",
    "            df_train = df.iloc[710:1421]\n",
    "            print('train' + \"\\t anomalies \" + str(df_train.loc[df_train['class']==1].shape[0]) + '\\t values ' + str(df_train.shape[0]))\n",
    "            print('\\n')\n",
    "            append_to_file(df_test, test_file_name)\n",
    "            append_to_file(df_train, train_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
