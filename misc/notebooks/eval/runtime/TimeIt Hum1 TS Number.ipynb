{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vadetisweb.anomaly_algorithms.detection.cluster import cluster_gaussian_mixture\n",
    "from vadetisweb.anomaly_algorithms.detection.histogram import histogram\n",
    "from vadetisweb.anomaly_algorithms.detection.svm import svm\n",
    "from vadetisweb.anomaly_algorithms.detection.isolation_forest import isolation_forest\n",
    "from vadetisweb.anomaly_algorithms.detection.lisa import lisa_pearson, lisa_dtw, lisa_geo\n",
    "from vadetisweb.anomaly_algorithms.detection.robust_pca import robust_pca_huber_loss\n",
    "from vadetisweb.models import DataSet, TimeSeries\n",
    "\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hum1 Single - TS NUMBER\n",
    "dataset_name = 'Humidity'\n",
    "ts_names = ['LUZ', 'RGNOT', 'MOA', 'KOP', 'LAG', 'OBR', 'LAE', 'ORO', 'PAY']\n",
    "ts_name_lisa = 'LUZ'\n",
    "dimensions = [2, 3, 4, 5, 6, 7, 8, 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input\n",
    "def get_dataset(title):\n",
    "    dataset = DataSet.objects.filter(title=title).first()\n",
    "    training_dataset = dataset.training_dataset.all().first()\n",
    "    return dataset, training_dataset\n",
    "\n",
    "def get_ts_ids(dataset, ts_names):\n",
    "    ts_ids = []\n",
    "    time_series = dataset.timeseries_set.all()\n",
    "    for ts in time_series:\n",
    "        if ts.name in ts_names:\n",
    "            ts_ids.append(ts.id)\n",
    "            \n",
    "    return ts_ids\n",
    "\n",
    "def get_lisa_detection_ts_id(dataset, ts_name):\n",
    "    time_series = dataset.timeseries_set.all()\n",
    "    for ts in time_series:\n",
    "        if ts.name == ts_name:\n",
    "            return ts.id\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lisa_pearson_detection_time_it(df, df_class, time_series_id, maximize_score='F1-Score', window_size=10):\n",
    "    result = %timeit -o lisa_pearson(df, df_class, time_series_id, maximize_score=maximize_score, window_size=window_size)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lisa_dtw_detection_time_it(df, df_class, time_series_id, maximize_score='F1-Score', window_size=10):\n",
    "    result = %timeit -o lisa_dtw(df, df_class, time_series_id, maximize_score=maximize_score, window_size=window_size, distance_function='euclidean')\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lisa_geo_detection_time_it(df, df_class, time_series_id, maximize_score='F1-Score'):\n",
    "    result = %timeit -o lisa_geo(df, df_class, time_series_id, maximize_score=maximize_score)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rpca_detection_time_it(df, df_class, df_train, df_train_class, delta=1, n_components=2, maximize_score='F1-Score', train_size=0.5):\n",
    "    result = %timeit -o robust_pca_huber_loss(df, df_class, df_train, df_train_class, delta=delta, n_components=n_components, maximize_score=maximize_score, train_size=train_size)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogram_detection_time_it(df, df_class, df_train, df_train_class, maximize_score='F1-Score', train_size=0.5):\n",
    "    result = %timeit -o histogram(df, df_class, df_train, df_train_class, maximize_score=maximize_score, train_size=train_size)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_detection_time_it(df, df_class, df_train, df_train_class, maximize_score='F1-Score', n_components=3, n_init=3, train_size=0.5):\n",
    "    result = %timeit -o cluster_gaussian_mixture(df, df_class, df_train, df_train_class, maximize_score=maximize_score, n_components=n_components, n_init=n_init, train_size=train_size)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_detection_time_it(df, df_class, df_train, df_train_class, maximize_score='F1-Score', nu=0.95, kernel='rbf', train_size=0.5):\n",
    "    result = %timeit -o svm(df, df_class, df_train, df_train_class, maximize_score=maximize_score, nu=nu, kernel=kernel, train_size=train_size)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isolation_forest_detection_time_it(df, df_class, df_train, df_train_class, maximize_score='F1-Score', n_jobs=-1, bootstrap=False, n_estimators=40, train_size=0.5):\n",
    "    result = %timeit -o isolation_forest(df, df_class, df_train, df_train_class, maximize_score=maximize_score, n_jobs=n_jobs, bootstrap=bootstrap, n_estimators=n_estimators, train_size=train_size)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.51 s ± 84.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "3.47 s ± 85.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "3.43 s ± 55.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "3.45 s ± 47.8 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "3.46 s ± 17.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "3.51 s ± 51.2 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "3.59 s ± 74.3 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "3.54 s ± 20.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# TIME TS NUMBER - Pearson\n",
    "dataset, training_dataset = get_dataset(dataset_name)\n",
    "\n",
    "lisa_pearson_results = []\n",
    "for l in dimensions:\n",
    "    set_names = ts_names[0:l]\n",
    "    ts_id = get_lisa_detection_ts_id(dataset, ts_name_lisa)\n",
    "    ts_ids = get_ts_ids(dataset, set_names)\n",
    "    \n",
    "    df = dataset.dataframe[ts_ids]\n",
    "    df_class = dataset.dataframe_class[ts_ids]\n",
    "    df_train = training_dataset.dataframe[ts_ids]\n",
    "    df_train_class = training_dataset.dataframe_class[ts_ids]\n",
    "    \n",
    "    r = lisa_pearson_detection_time_it(df, df_class, ts_id)\n",
    "    lisa_pearson_results.append(np.round(np.average(r.all_runs), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.35 s ± 50.8 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "6.37 s ± 134 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "7.35 s ± 142 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "8.43 s ± 93.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "9.34 s ± 65.8 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "10.3 s ± 91 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "11.4 s ± 220 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "12.3 s ± 119 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# TIME TS NUMBER - DTW\n",
    "dataset, training_dataset = get_dataset(dataset_name)\n",
    "\n",
    "lisa_dtw_results = []\n",
    "for l in dimensions:\n",
    "    set_names = ts_names[0:l]\n",
    "    ts_id = get_lisa_detection_ts_id(dataset, ts_name_lisa)\n",
    "    ts_ids = get_ts_ids(dataset, set_names)\n",
    "    \n",
    "    df = dataset.dataframe[ts_ids]\n",
    "    df_class = dataset.dataframe_class[ts_ids]\n",
    "    df_train = training_dataset.dataframe[ts_ids]\n",
    "    df_train_class = training_dataset.dataframe_class[ts_ids]\n",
    "    \n",
    "    r = lisa_dtw_detection_time_it(df, df_class, ts_id)\n",
    "    lisa_dtw_results.append(np.round(np.average(r.all_runs), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.4 s ± 34.8 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "3.53 s ± 46.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "3.56 s ± 31.3 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "3.6 s ± 37.3 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "3.63 s ± 41.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "3.68 s ± 34.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "3.71 s ± 39 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "3.77 s ± 48.8 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# TIME TS NUMBER - LISA VANILLA\n",
    "dataset, training_dataset = get_dataset(dataset_name)\n",
    "lisa_geo_results = []\n",
    "for l in dimensions:\n",
    "    set_names = ts_names[0:l]\n",
    "    ts_id = get_lisa_detection_ts_id(dataset, ts_name_lisa)\n",
    "    ts_ids = get_ts_ids(dataset, set_names)\n",
    "    \n",
    "    df = dataset.dataframe[ts_ids]\n",
    "    df_class = dataset.dataframe_class[ts_ids]\n",
    "    df_train = training_dataset.dataframe[ts_ids]\n",
    "    df_train_class = training_dataset.dataframe_class[ts_ids]\n",
    "    \n",
    "    r = lisa_geo_detection_time_it(df, df_class, ts_id)\n",
    "    lisa_geo_results.append(np.round(np.average(r.all_runs), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.74 s ± 39.2 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "2.84 s ± 52.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "2.82 s ± 84 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "2.93 s ± 80.2 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "2.93 s ± 69.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "2.88 s ± 48.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "2.96 s ± 80.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "3.03 s ± 47.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# TIME TS NUMBER - RPCA\n",
    "dataset, training_dataset = get_dataset(dataset_name)\n",
    "rpca_results = []\n",
    "for l in dimensions:\n",
    "    set_names = ts_names[0:l]\n",
    "    ts_ids = get_ts_ids(dataset, set_names)\n",
    "    \n",
    "    df = dataset.dataframe[ts_ids]\n",
    "    df_class = dataset.dataframe_class[ts_ids]\n",
    "    df_train = training_dataset.dataframe[ts_ids]\n",
    "    df_train_class = training_dataset.dataframe_class[ts_ids]\n",
    "    \n",
    "    r = rpca_detection_time_it(df, df_class, df_train, df_train_class)\n",
    "    rpca_results.append(np.round(np.average(r.all_runs), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.73 s ± 2.17 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "2.84 s ± 106 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "2.92 s ± 57.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "2.98 s ± 66 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "2.97 s ± 44.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "3.02 s ± 54.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "3.09 s ± 81.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "3.08 s ± 65.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# TIME TS NUMBER - HISTOGRAM\n",
    "dataset, training_dataset = get_dataset(dataset_name)\n",
    "\n",
    "histogram_results = []\n",
    "for l in dimensions:\n",
    "    set_names = ts_names[0:l]\n",
    "    ts_ids = get_ts_ids(dataset, set_names)\n",
    "    \n",
    "    df = dataset.dataframe[ts_ids]\n",
    "    df_class = dataset.dataframe_class[ts_ids]\n",
    "    df_train = training_dataset.dataframe[ts_ids]\n",
    "    df_train_class = training_dataset.dataframe_class[ts_ids]\n",
    "    \n",
    "    r = histogram_detection_time_it(df, df_class, df_train, df_train_class)\n",
    "    histogram_results.append(np.round(np.average(r.all_runs), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.73 s ± 1.89 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "2.84 s ± 71 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "2.84 s ± 63.3 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "2.91 s ± 44.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "2.88 s ± 48.3 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "2.94 s ± 76.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "3.03 s ± 56.2 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "3.01 s ± 66.3 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# TIME TS NUMBER - CLUSTER\n",
    "dataset, training_dataset = get_dataset(dataset_name)\n",
    "cluster_results = []\n",
    "for l in dimensions:\n",
    "    set_names = ts_names[0:l]\n",
    "    ts_ids = get_ts_ids(dataset, set_names)\n",
    "    \n",
    "    df = dataset.dataframe[ts_ids]\n",
    "    df_class = dataset.dataframe_class[ts_ids]\n",
    "    df_train = training_dataset.dataframe[ts_ids]\n",
    "    df_train_class = training_dataset.dataframe_class[ts_ids]\n",
    "    \n",
    "    r = cluster_detection_time_it(df, df_class, df_train, df_train_class)\n",
    "    cluster_results.append(np.round(np.average(r.all_runs), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.81 s ± 39.3 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "2.82 s ± 44.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "2.87 s ± 56.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "2.94 s ± 64.3 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "2.95 s ± 63.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "2.96 s ± 68.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "3.1 s ± 38.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "2.97 s ± 67.8 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# TIME TS NUMBER - SVM\n",
    "dataset, training_dataset = get_dataset(dataset_name)\n",
    "svm_results = []\n",
    "for l in dimensions:\n",
    "    set_names = ts_names[0:l]\n",
    "    ts_ids = get_ts_ids(dataset, set_names)\n",
    "    \n",
    "    df = dataset.dataframe[ts_ids]\n",
    "    df_class = dataset.dataframe_class[ts_ids]\n",
    "    df_train = training_dataset.dataframe[ts_ids]\n",
    "    df_train_class = training_dataset.dataframe_class[ts_ids]\n",
    "    \n",
    "    r = svm_detection_time_it(df, df_class, df_train, df_train_class)\n",
    "    svm_results.append(np.round(np.average(r.all_runs), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1 s ± 52.3 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "3.16 s ± 26.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "3.2 s ± 29.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "3.23 s ± 33 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "3.25 s ± 32.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "3.26 s ± 71.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "3.32 s ± 37.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "3.32 s ± 58.8 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# TIME TS NUMBER - ISOLATION FOREST\n",
    "dataset, training_dataset = get_dataset(dataset_name)\n",
    "\n",
    "isolation_results = []\n",
    "for l in dimensions:\n",
    "    set_names = ts_names[0:l]\n",
    "    ts_ids = get_ts_ids(dataset, set_names)\n",
    "    \n",
    "    df = dataset.dataframe[ts_ids]\n",
    "    df_class = dataset.dataframe_class[ts_ids]\n",
    "    df_train = training_dataset.dataframe[ts_ids]\n",
    "    df_train_class = training_dataset.dataframe_class[ts_ids]\n",
    "    \n",
    "    r = isolation_forest_detection_time_it(df, df_class, df_train, df_train_class)\n",
    "    isolation_results.append(np.round(np.average(r.all_runs), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = [{ 'title' : 'LISA (Pearson)', 'scores' : lisa_pearson_results }, \n",
    "          { 'title' : 'LISA (DTW)', 'scores' : lisa_dtw_results }, \n",
    "          { 'title' : 'LISA (Vanilla)', 'scores' :  lisa_geo_results }, \n",
    "          { 'title' : 'RPCA', 'scores' :  rpca_results }, \n",
    "          { 'title' : 'Histogram', 'scores' :  histogram_results }, \n",
    "          { 'title' : 'Cluster', 'scores' :  cluster_results }, \n",
    "          { 'title' : 'SVM', 'scores' :  svm_results }, \n",
    "          { 'title' : 'Isolation Forest', 'scores' :  isolation_results }\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'title': 'LISA (Pearson)', 'scores': [3.51, 3.47, 3.43, 3.45, 3.46, 3.51, 3.59, 3.54]}, {'title': 'LISA (DTW)', 'scores': [5.35, 6.37, 7.35, 8.43, 9.34, 10.29, 11.39, 12.28]}, {'title': 'LISA (Vanilla)', 'scores': [3.4, 3.53, 3.56, 3.6, 3.63, 3.68, 3.71, 3.77]}, {'title': 'RPCA', 'scores': [2.74, 2.84, 2.82, 2.93, 2.93, 2.88, 2.96, 3.03]}, {'title': 'Histogram', 'scores': [2.73, 2.84, 2.92, 2.98, 2.97, 3.02, 3.09, 3.08]}, {'title': 'Cluster', 'scores': [2.73, 2.84, 2.84, 2.91, 2.88, 2.94, 3.03, 3.01]}, {'title': 'SVM', 'scores': [2.81, 2.82, 2.87, 2.94, 2.95, 2.96, 3.1, 2.97]}, {'title': 'Isolation Forest', 'scores': [3.1, 3.16, 3.2, 3.23, 3.25, 3.26, 3.32, 3.32]}]\n"
     ]
    }
   ],
   "source": [
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "scores = [{'title': 'LISA (Pearson)', 'scores': [3.51, 3.47, 3.43, 3.45, 3.46, 3.51, 3.59, 3.54]}, {'title': 'LISA (DTW)', 'scores': [5.35, 6.37, 7.35, 8.43, 9.34, 10.29, 11.39, 12.28]}, {'title': 'LISA (Vanilla)', 'scores': [3.4, 3.53, 3.56, 3.6, 3.63, 3.68, 3.71, 3.77]}, {'title': 'RPCA', 'scores': [2.74, 2.84, 2.82, 2.93, 2.93, 2.88, 2.96, 3.03]}, {'title': 'Histogram', 'scores': [2.73, 2.84, 2.92, 2.98, 2.97, 3.02, 3.09, 3.08]}, {'title': 'Cluster', 'scores': [2.73, 2.84, 2.84, 2.91, 2.88, 2.94, 3.03, 3.01]}, {'title': 'SVM', 'scores': [2.81, 2.82, 2.87, 2.94, 2.95, 2.96, 3.1, 2.97]}, {'title': 'Isolation Forest', 'scores': [3.1, 3.16, 3.2, 3.23, 3.25, 3.26, 3.32, 3.32]}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for score in scores:\n",
    "    res = []\n",
    "    values = score['scores']\n",
    "    for i in range(len(dimensions)):\n",
    "        dim = dimensions[i]\n",
    "        val = int(values[i]*1000)\n",
    "        res.append((dim, val))\n",
    "    results.append({'title' : score['title'], 'plotdata' : res}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   {   'plotdata': [   (2, 3510),\n",
      "                        (3, 3470),\n",
      "                        (4, 3430),\n",
      "                        (5, 3450),\n",
      "                        (6, 3460),\n",
      "                        (7, 3510),\n",
      "                        (8, 3590),\n",
      "                        (9, 3540)],\n",
      "        'title': 'LISA (Pearson)'},\n",
      "    {   'plotdata': [   (2, 5350),\n",
      "                        (3, 6370),\n",
      "                        (4, 7350),\n",
      "                        (5, 8430),\n",
      "                        (6, 9340),\n",
      "                        (7, 10290),\n",
      "                        (8, 11390),\n",
      "                        (9, 12280)],\n",
      "        'title': 'LISA (DTW)'},\n",
      "    {   'plotdata': [   (2, 3400),\n",
      "                        (3, 3530),\n",
      "                        (4, 3560),\n",
      "                        (5, 3600),\n",
      "                        (6, 3630),\n",
      "                        (7, 3680),\n",
      "                        (8, 3710),\n",
      "                        (9, 3770)],\n",
      "        'title': 'LISA (Vanilla)'},\n",
      "    {   'plotdata': [   (2, 2740),\n",
      "                        (3, 2840),\n",
      "                        (4, 2820),\n",
      "                        (5, 2930),\n",
      "                        (6, 2930),\n",
      "                        (7, 2880),\n",
      "                        (8, 2960),\n",
      "                        (9, 3030)],\n",
      "        'title': 'RPCA'},\n",
      "    {   'plotdata': [   (2, 2730),\n",
      "                        (3, 2840),\n",
      "                        (4, 2920),\n",
      "                        (5, 2980),\n",
      "                        (6, 2970),\n",
      "                        (7, 3020),\n",
      "                        (8, 3090),\n",
      "                        (9, 3080)],\n",
      "        'title': 'Histogram'},\n",
      "    {   'plotdata': [   (2, 2730),\n",
      "                        (3, 2840),\n",
      "                        (4, 2840),\n",
      "                        (5, 2910),\n",
      "                        (6, 2880),\n",
      "                        (7, 2940),\n",
      "                        (8, 3030),\n",
      "                        (9, 3010)],\n",
      "        'title': 'Cluster'},\n",
      "    {   'plotdata': [   (2, 2810),\n",
      "                        (3, 2820),\n",
      "                        (4, 2870),\n",
      "                        (5, 2940),\n",
      "                        (6, 2950),\n",
      "                        (7, 2960),\n",
      "                        (8, 3100),\n",
      "                        (9, 2970)],\n",
      "        'title': 'SVM'},\n",
      "    {   'plotdata': [   (2, 3100),\n",
      "                        (3, 3160),\n",
      "                        (4, 3200),\n",
      "                        (5, 3230),\n",
      "                        (6, 3250),\n",
      "                        (7, 3260),\n",
      "                        (8, 3320),\n",
      "                        (9, 3320)],\n",
      "        'title': 'Isolation Forest'}]\n"
     ]
    }
   ],
   "source": [
    "pp.pprint(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
