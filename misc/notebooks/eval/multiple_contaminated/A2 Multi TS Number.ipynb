{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vadetisweb.anomaly_algorithms.detection.cluster import cluster_gaussian_mixture\n",
    "from vadetisweb.anomaly_algorithms.detection.histogram import histogram\n",
    "from vadetisweb.anomaly_algorithms.detection.svm import svm\n",
    "from vadetisweb.anomaly_algorithms.detection.isolation_forest import isolation_forest\n",
    "from vadetisweb.anomaly_algorithms.detection.lisa import lisa_pearson, lisa_dtw, lisa_geo\n",
    "from vadetisweb.anomaly_algorithms.detection.robust_pca import robust_pca_huber_loss\n",
    "from vadetisweb.models import DataSet, TimeSeries\n",
    "\n",
    "import numpy as np\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A2 Multi - TS NUMBER\n",
    "dataset_name = 'A2 Yahoo'\n",
    "ts_names = ['TS' + str(x) for x in [24, 66, 3, 10, 45, 17, 87, 73, 31, 38]]\n",
    "dimensions = [4, 5, 6, 7, 8, 9, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input\n",
    "def get_dataset(title):\n",
    "    dataset = DataSet.objects.filter(title=title).first()\n",
    "    training_dataset = dataset.training_dataset.all().first()\n",
    "    return dataset, training_dataset\n",
    "\n",
    "def get_ts_ids(dataset, ts_names):\n",
    "    ts_ids = []\n",
    "    time_series = dataset.timeseries_set.all()\n",
    "    for ts in time_series:\n",
    "        if ts.name in ts_names:\n",
    "            ts_ids.append(ts.id)\n",
    "            \n",
    "    return ts_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rpca_detection_l(df, df_class, df_train, df_train_class, delta=1, n_components=2, maximize_score='F1-Score', train_size=0.5):\n",
    "    return robust_pca_huber_loss(df, df_class, df_train, df_train_class, delta=delta, n_components=n_components, maximize_score=maximize_score, train_size=train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogram_detection_l(df, df_class, df_train, df_train_class, maximize_score='F1-Score', train_size=0.5):\n",
    "    return histogram(df, df_class, df_train, df_train_class, maximize_score=maximize_score, train_size=train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_detection_l(df, df_class, df_train, df_train_class, maximize_score='F1-Score', n_components=3, n_init=3, train_size=0.5):\n",
    "    return cluster_gaussian_mixture(df, df_class, df_train, df_train_class, maximize_score=maximize_score, n_components=n_components, n_init=n_init, train_size=train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_detection_l(df, df_class, df_train, df_train_class, maximize_score='F1-Score', nu=0.95, kernel='rbf', train_size=0.5):\n",
    "    return svm(df, df_class, df_train, df_train_class, maximize_score=maximize_score, nu=nu, kernel=kernel, train_size=train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isolation_forest_detection_l(df, df_class, df_train, df_train_class, maximize_score='F1-Score', n_jobs=-1, bootstrap=False, n_estimators=40, train_size=0.5):\n",
    "    return isolation_forest(df, df_class, df_train, df_train_class, maximize_score=maximize_score, n_jobs=n_jobs, bootstrap=bootstrap, n_estimators=n_estimators, train_size=train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TS NUMBER - RPCA\n",
    "dataset, training_dataset = get_dataset(dataset_name)\n",
    "# Results array [nmi, rmse, f1]\n",
    "r_results = []\n",
    "for l in dimensions:\n",
    "    set_names = ts_names[0:l]\n",
    "    ts_ids = get_ts_ids(dataset, set_names)\n",
    "    \n",
    "    df = dataset.dataframe[ts_ids]\n",
    "    df_class = dataset.dataframe_class[ts_ids]\n",
    "    df_train = training_dataset.dataframe[ts_ids]\n",
    "    df_train_class = training_dataset.dataframe_class[ts_ids]\n",
    "    \n",
    "    scores, y_hat_results, df_common_class, info = rpca_detection_l(df, df_class, df_train, df_train_class)\n",
    "    result = [np.round(info['nmi'], 3), np.round(info['rmse'], 3), np.round(info['f1_score'], 3)]\n",
    "    r_results.append(result)\n",
    "    \n",
    "rpca_results = np.array(r_results)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TS NUMBER - HISTOGRAM\n",
    "dataset, training_dataset = get_dataset(dataset_name)\n",
    "\n",
    "# Results array [nmi, rmse, f1]\n",
    "h_results = []\n",
    "for l in dimensions:\n",
    "    set_names = ts_names[0:l]\n",
    "    ts_ids = get_ts_ids(dataset, set_names)\n",
    "    \n",
    "    df = dataset.dataframe[ts_ids]\n",
    "    df_class = dataset.dataframe_class[ts_ids]\n",
    "    df_train = training_dataset.dataframe[ts_ids]\n",
    "    df_train_class = training_dataset.dataframe_class[ts_ids]\n",
    "    \n",
    "    scores, y_hat_results, df_common_class, info = histogram_detection_l(df, df_class, df_train, df_train_class)\n",
    "    result = [np.round(info['nmi'], 3), np.round(info['rmse'], 3), np.round(info['f1_score'], 3)]\n",
    "    h_results.append(result)\n",
    "    \n",
    "histogram_results = np.array(h_results)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TS NUMBER - CLUSTER\n",
    "dataset, training_dataset = get_dataset(dataset_name)\n",
    "\n",
    "# Results array [nmi, rmse, f1]\n",
    "c_results = []\n",
    "for l in dimensions:\n",
    "    set_names = ts_names[0:l]\n",
    "    ts_ids = get_ts_ids(dataset, set_names)\n",
    "    \n",
    "    df = dataset.dataframe[ts_ids]\n",
    "    df_class = dataset.dataframe_class[ts_ids]\n",
    "    df_train = training_dataset.dataframe[ts_ids]\n",
    "    df_train_class = training_dataset.dataframe_class[ts_ids]\n",
    "    \n",
    "    scores, y_hat_results, df_common_class, info = cluster_detection_l(df, df_class, df_train, df_train_class)\n",
    "    result = [np.round(info['nmi'], 3), np.round(info['rmse'], 3), np.round(info['f1_score'], 3)]\n",
    "    c_results.append(result)\n",
    "    \n",
    "cluster_results = np.array(c_results)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TS NUMBER - SVM\n",
    "dataset, training_dataset = get_dataset(dataset_name)\n",
    "\n",
    "# Results array [nmi, rmse, f1]\n",
    "s_results = []\n",
    "for l in dimensions:\n",
    "    set_names = ts_names[0:l]\n",
    "    ts_ids = get_ts_ids(dataset, set_names)\n",
    "    \n",
    "    df = dataset.dataframe[ts_ids]\n",
    "    df_class = dataset.dataframe_class[ts_ids]\n",
    "    df_train = training_dataset.dataframe[ts_ids]\n",
    "    df_train_class = training_dataset.dataframe_class[ts_ids]\n",
    "    \n",
    "    scores, y_hat_results, df_common_class, info = svm_detection_l(df, df_class, df_train, df_train_class)\n",
    "    result = [np.round(info['nmi'], 3), np.round(info['rmse'], 3), np.round(info['f1_score'], 3)]\n",
    "    s_results.append(result)\n",
    "    \n",
    "svm_results = np.array(s_results)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TS NUMBER - ISOLATION FOREST\n",
    "dataset, training_dataset = get_dataset(dataset_name)\n",
    "\n",
    "# Results array [nmi, rmse, f1]\n",
    "i_results = []\n",
    "for l in dimensions:\n",
    "    set_names = ts_names[0:l]\n",
    "    ts_ids = get_ts_ids(dataset, set_names)\n",
    "    \n",
    "    df = dataset.dataframe[ts_ids]\n",
    "    df_class = dataset.dataframe_class[ts_ids]\n",
    "    df_train = training_dataset.dataframe[ts_ids]\n",
    "    df_train_class = training_dataset.dataframe_class[ts_ids]\n",
    "    \n",
    "    scores, y_hat_results, df_common_class, info = isolation_forest_detection_l(df, df_class, df_train, df_train_class)\n",
    "    result = [np.round(info['nmi'], 3), np.round(info['rmse'], 3), np.round(info['f1_score'], 3)]\n",
    "    i_results.append(result)\n",
    "\n",
    "isolation_results = np.array(i_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rpca_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-d37a7c246a0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m scores = [{ 'title' : 'RPCA', 'scores' :  rpca_results }, \n\u001b[0m\u001b[1;32m      2\u001b[0m           \u001b[0;34m{\u001b[0m \u001b[0;34m'title'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m'Histogram'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'scores'\u001b[0m \u001b[0;34m:\u001b[0m  \u001b[0mhistogram_results\u001b[0m \u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m           \u001b[0;34m{\u001b[0m \u001b[0;34m'title'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m'Cluster'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'scores'\u001b[0m \u001b[0;34m:\u001b[0m  \u001b[0mcluster_results\u001b[0m \u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m           \u001b[0;34m{\u001b[0m \u001b[0;34m'title'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m'SVM'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'scores'\u001b[0m \u001b[0;34m:\u001b[0m  \u001b[0msvm_results\u001b[0m \u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m           \u001b[0;34m{\u001b[0m \u001b[0;34m'title'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m'Isolation Forest'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'scores'\u001b[0m \u001b[0;34m:\u001b[0m  \u001b[0misolation_results\u001b[0m \u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rpca_results' is not defined"
     ]
    }
   ],
   "source": [
    "scores = [{ 'title' : 'RPCA', 'scores' :  rpca_results }, \n",
    "          { 'title' : 'Histogram', 'scores' :  histogram_results }, \n",
    "          { 'title' : 'Cluster', 'scores' :  cluster_results }, \n",
    "          { 'title' : 'SVM', 'scores' :  svm_results }, \n",
    "          { 'title' : 'Isolation Forest', 'scores' :  isolation_results }\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'title': 'RPCA', 'scores': array([[0.75 , 0.011, 0.867],\n",
      "       [0.254, 0.139, 0.407],\n",
      "       [0.837, 0.007, 0.937],\n",
      "       [0.191, 0.19 , 0.354],\n",
      "       [0.134, 0.249, 0.289],\n",
      "       [0.096, 0.127, 0.318],\n",
      "       [0.114, 0.106, 0.348]])}, {'title': 'Histogram', 'scores': array([[0.011, 0.507, 0.048],\n",
      "       [0.011, 0.531, 0.05 ],\n",
      "       [0.006, 0.63 , 0.075],\n",
      "       [0.008, 0.69 , 0.075],\n",
      "       [0.01 , 0.7  , 0.074],\n",
      "       [0.011, 0.911, 0.105],\n",
      "       [0.002, 0.896, 0.104]])}, {'title': 'Cluster', 'scores': array([[0.366, 0.032, 0.489],\n",
      "       [0.154, 0.042, 0.211],\n",
      "       [0.404, 0.034, 0.538],\n",
      "       [0.609, 0.021, 0.754],\n",
      "       [0.897, 0.004, 0.959],\n",
      "       [0.897, 0.004, 0.959],\n",
      "       [0.897, 0.004, 0.959]])}, {'title': 'SVM', 'scores': array([[0.31 , 0.035, 0.419],\n",
      "       [0.325, 0.034, 0.52 ],\n",
      "       [0.31 , 0.041, 0.554],\n",
      "       [0.109, 0.097, 0.343],\n",
      "       [0.079, 0.121, 0.295],\n",
      "       [0.07 , 0.115, 0.281],\n",
      "       [0.052, 0.089, 0.241]])}, {'title': 'Isolation Forest', 'scores': array([[0.116, 0.08 , 0.345],\n",
      "       [0.075, 0.189, 0.256],\n",
      "       [0.03 , 0.168, 0.201],\n",
      "       [0.044, 0.497, 0.165],\n",
      "       [0.026, 0.421, 0.162],\n",
      "       [0.025, 0.508, 0.151],\n",
      "       [0.042, 0.507, 0.163]])}]\n"
     ]
    }
   ],
   "source": [
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# scores = [{'title': 'RPCA', 'scores': np.array([[0.75 , 0.011, 0.867],\n",
    "#        [0.254, 0.139, 0.407],\n",
    "#        [0.837, 0.007, 0.937],\n",
    "#        [0.191, 0.19 , 0.354],\n",
    "#        [0.134, 0.249, 0.289],\n",
    "#        [0.096, 0.127, 0.318],\n",
    "#        [0.114, 0.106, 0.348]])}, {'title': 'Histogram', 'scores': np.array([[0.011, 0.507, 0.048],\n",
    "#        [0.011, 0.531, 0.05 ],\n",
    "#        [0.006, 0.63 , 0.075],\n",
    "#        [0.008, 0.69 , 0.075],\n",
    "#        [0.01 , 0.7  , 0.074],\n",
    "#        [0.011, 0.911, 0.105],\n",
    "#        [0.002, 0.896, 0.104]])}, {'title': 'Cluster', 'scores': np.array([[0.366, 0.032, 0.489],\n",
    "#        [0.154, 0.042, 0.211],\n",
    "#        [0.404, 0.034, 0.538],\n",
    "#        [0.609, 0.021, 0.754],\n",
    "#        [0.897, 0.004, 0.959],\n",
    "#        [0.897, 0.004, 0.959],\n",
    "#        [0.897, 0.004, 0.959]])}, {'title': 'SVM', 'scores': np.array([[0.31 , 0.035, 0.419],\n",
    "#        [0.325, 0.034, 0.52 ],\n",
    "#        [0.31 , 0.041, 0.554],\n",
    "#        [0.109, 0.097, 0.343],\n",
    "#        [0.079, 0.121, 0.295],\n",
    "#        [0.07 , 0.115, 0.281],\n",
    "#        [0.052, 0.089, 0.241]])}, {'title': 'Isolation Forest', 'scores': np.array([[0.116, 0.08 , 0.345],\n",
    "#        [0.075, 0.189, 0.256],\n",
    "#        [0.03 , 0.168, 0.201],\n",
    "#        [0.044, 0.497, 0.165],\n",
    "#        [0.026, 0.421, 0.162],\n",
    "#        [0.025, 0.508, 0.151],\n",
    "#        [0.042, 0.507, 0.163]])}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NMI\n",
    "results = []\n",
    "for score in scores:\n",
    "    res = []\n",
    "    values = score['scores']\n",
    "    for i in range(len(dimensions)):\n",
    "        dim = dimensions[i]\n",
    "        val = values[i][0]\n",
    "        res.append((dim, val))\n",
    "    results.append({'title' : score['title'], 'plotdata' : res}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   {   'plotdata': [   (4, 0.75),\n",
      "                        (5, 0.254),\n",
      "                        (6, 0.837),\n",
      "                        (7, 0.191),\n",
      "                        (8, 0.134),\n",
      "                        (9, 0.096),\n",
      "                        (10, 0.114)],\n",
      "        'title': 'RPCA'},\n",
      "    {   'plotdata': [   (4, 0.011),\n",
      "                        (5, 0.011),\n",
      "                        (6, 0.006),\n",
      "                        (7, 0.008),\n",
      "                        (8, 0.01),\n",
      "                        (9, 0.011),\n",
      "                        (10, 0.002)],\n",
      "        'title': 'Histogram'},\n",
      "    {   'plotdata': [   (4, 0.366),\n",
      "                        (5, 0.154),\n",
      "                        (6, 0.404),\n",
      "                        (7, 0.609),\n",
      "                        (8, 0.897),\n",
      "                        (9, 0.897),\n",
      "                        (10, 0.897)],\n",
      "        'title': 'Cluster'},\n",
      "    {   'plotdata': [   (4, 0.31),\n",
      "                        (5, 0.325),\n",
      "                        (6, 0.31),\n",
      "                        (7, 0.109),\n",
      "                        (8, 0.079),\n",
      "                        (9, 0.07),\n",
      "                        (10, 0.052)],\n",
      "        'title': 'SVM'},\n",
      "    {   'plotdata': [   (4, 0.116),\n",
      "                        (5, 0.075),\n",
      "                        (6, 0.03),\n",
      "                        (7, 0.044),\n",
      "                        (8, 0.026),\n",
      "                        (9, 0.025),\n",
      "                        (10, 0.042)],\n",
      "        'title': 'Isolation Forest'}]\n"
     ]
    }
   ],
   "source": [
    "pp.pprint(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RMSE\n",
    "results = []\n",
    "for score in scores:\n",
    "    res = []\n",
    "    values = score['scores']\n",
    "    for i in range(len(dimensions)):\n",
    "        dim = dimensions[i]\n",
    "        val = values[i][1]\n",
    "        res.append((dim, val))\n",
    "    results.append({'title' : score['title'], 'plotdata' : res}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   {   'plotdata': [   (4, 0.011),\n",
      "                        (5, 0.139),\n",
      "                        (6, 0.007),\n",
      "                        (7, 0.19),\n",
      "                        (8, 0.249),\n",
      "                        (9, 0.127),\n",
      "                        (10, 0.106)],\n",
      "        'title': 'RPCA'},\n",
      "    {   'plotdata': [   (4, 0.507),\n",
      "                        (5, 0.531),\n",
      "                        (6, 0.63),\n",
      "                        (7, 0.69),\n",
      "                        (8, 0.7),\n",
      "                        (9, 0.911),\n",
      "                        (10, 0.896)],\n",
      "        'title': 'Histogram'},\n",
      "    {   'plotdata': [   (4, 0.032),\n",
      "                        (5, 0.042),\n",
      "                        (6, 0.034),\n",
      "                        (7, 0.021),\n",
      "                        (8, 0.004),\n",
      "                        (9, 0.004),\n",
      "                        (10, 0.004)],\n",
      "        'title': 'Cluster'},\n",
      "    {   'plotdata': [   (4, 0.035),\n",
      "                        (5, 0.034),\n",
      "                        (6, 0.041),\n",
      "                        (7, 0.097),\n",
      "                        (8, 0.121),\n",
      "                        (9, 0.115),\n",
      "                        (10, 0.089)],\n",
      "        'title': 'SVM'},\n",
      "    {   'plotdata': [   (4, 0.08),\n",
      "                        (5, 0.189),\n",
      "                        (6, 0.168),\n",
      "                        (7, 0.497),\n",
      "                        (8, 0.421),\n",
      "                        (9, 0.508),\n",
      "                        (10, 0.507)],\n",
      "        'title': 'Isolation Forest'}]\n"
     ]
    }
   ],
   "source": [
    "pp.pprint(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#F1\n",
    "results = []\n",
    "for score in scores:\n",
    "    res = []\n",
    "    values = score['scores']\n",
    "    for i in range(len(dimensions)):\n",
    "        dim = dimensions[i]\n",
    "        val = values[i][2]\n",
    "        res.append((dim, val))\n",
    "    results.append({'title' : score['title'], 'plotdata' : res}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   {   'plotdata': [   (4, 0.867),\n",
      "                        (5, 0.407),\n",
      "                        (6, 0.937),\n",
      "                        (7, 0.354),\n",
      "                        (8, 0.289),\n",
      "                        (9, 0.318),\n",
      "                        (10, 0.348)],\n",
      "        'title': 'RPCA'},\n",
      "    {   'plotdata': [   (4, 0.048),\n",
      "                        (5, 0.05),\n",
      "                        (6, 0.075),\n",
      "                        (7, 0.075),\n",
      "                        (8, 0.074),\n",
      "                        (9, 0.105),\n",
      "                        (10, 0.104)],\n",
      "        'title': 'Histogram'},\n",
      "    {   'plotdata': [   (4, 0.489),\n",
      "                        (5, 0.211),\n",
      "                        (6, 0.538),\n",
      "                        (7, 0.754),\n",
      "                        (8, 0.959),\n",
      "                        (9, 0.959),\n",
      "                        (10, 0.959)],\n",
      "        'title': 'Cluster'},\n",
      "    {   'plotdata': [   (4, 0.419),\n",
      "                        (5, 0.52),\n",
      "                        (6, 0.554),\n",
      "                        (7, 0.343),\n",
      "                        (8, 0.295),\n",
      "                        (9, 0.281),\n",
      "                        (10, 0.241)],\n",
      "        'title': 'SVM'},\n",
      "    {   'plotdata': [   (4, 0.345),\n",
      "                        (5, 0.256),\n",
      "                        (6, 0.201),\n",
      "                        (7, 0.165),\n",
      "                        (8, 0.162),\n",
      "                        (9, 0.151),\n",
      "                        (10, 0.163)],\n",
      "        'title': 'Isolation Forest'}]\n"
     ]
    }
   ],
   "source": [
    "pp.pprint(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
